#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pipeline consistent with the paper (FSL):
T1 → fslreorient2std → BET → FLIRT (2mm) → FNIRT (2mm config + refmask) → invwarp → applywarp (nn) AAL-90 MNI → native
→ ISO 1 mm → (optional LCC 26c) → SURFACE (grad/erode) → fractalbrain (FD) → CSV.

Run on Linux/WSL with FSL (BET/FLIRT/FNIRT/APPLYWARP) installed and on PATH.
"""

import os, sys, argparse, subprocess, shutil, glob
import numpy as np
import nibabel as nib
from nilearn import datasets, image as nlimage
from scipy.ndimage import (
    binary_erosion, binary_dilation, binary_opening, binary_closing,
    label, generate_binary_structure
)

# -----------------------
# Utils
# -----------------------
def run(cmd, env=None, cwd=None):
    print("[RUN]", " ".join(cmd))
    subprocess.check_call(cmd, env=env, cwd=cwd)

def check_fsl():
    for exe in ["fslreorient2std", "bet", "flirt", "fnirt", "invwarp", "applywarp"]:
        if shutil.which(exe) is None:
            raise RuntimeError(f"[ERROR] FSL binary not found: {exe}. Check your PATH/FSL installation.")
    if os.environ.get("FSLDIR") is None:
        print("[WARN] FSLDIR is not set. OK if FSL binaries are on PATH.")

def save_nifti_like(img_nii, out_path):
    nib.save(img_nii, out_path)

# -----------------------
# AAL helpers
# -----------------------
def aal90_ids_from_nilearn_values_correct():
    """
    AAL IDs for AAL-90:
    - use nilearn's official LUT: indices (values) <-> labels
    - exclude only Cerebellum* and Vermis*
    - keep subcortical structures
    """
    atlas = datasets.fetch_atlas_aal(version="SPM12")
    indices = list(map(int, atlas["indices"]))
    labels  = atlas["labels"]
    lut = dict(zip(indices, labels))
    keep = set()
    for val, name in lut.items():
        low = name.lower()
        if ("cerebel" in low) or ("vermis" in low):
            continue
        keep.add(int(val))
    return keep

def explode_atlas_to_rois(atlas_path, out_dir, keep_ids=None):
    os.makedirs(out_dir, exist_ok=True)
    atlas = nib.load(atlas_path)
    datai = np.rint(atlas.get_fdata()).astype(np.int32)
    aff   = atlas.affine
    hdr   = atlas.header
    all_labels = np.unique(datai)
    all_labels = all_labels[all_labels != 0]
    labels = [int(l) for l in all_labels if (keep_ids is None or int(l) in keep_ids)]

    print(f"[DBG] explode: raw_nonzero={len(all_labels)}, selected={len(labels)}")
    if labels:
        print("[DBG] sample kept IDs (first 10):", sorted(labels)[:10])

    saved = 0
    for rid in sorted(labels):
        mask = (datai == rid).astype(np.uint8)
        if mask.sum() == 0:
            continue
        out_path = os.path.join(out_dir, f"roi-{rid:04d}.nii.gz")
        nib.save(nib.Nifti1Image(mask, aff, hdr), out_path)
        saved += 1
    return saved

# -----------------------
# ISO 1 mm + (optional) cleanup + surface
# -----------------------
def keep_largest_cc_26(vol_bool: np.ndarray) -> np.ndarray:
    """Keep only the largest 26-connected component (reduces small islands)."""
    struct = generate_binary_structure(3, 3)  # 26c
    lab, n = label(vol_bool, structure=struct)
    if n <= 1:
        return vol_bool
    counts = np.bincount(lab.ravel())
    counts[0] = 0  # background
    k = counts.argmax()
    return (lab == k)

# NEW: remove small clusters (26c) based on voxel or mm3 thresholds
def remove_small_components_26(vol_bool: np.ndarray, zooms, min_vox=0, min_mm3=0.0) -> np.ndarray:
    """
    Remove 26c connected components smaller than min_vox or min_mm3.
    If both min_vox and min_mm3 > 0, both criteria must be met (AND).
    """
    if not np.any(vol_bool):
        return vol_bool

    struct = generate_binary_structure(3, 3)  # 26c
    lab, n = label(vol_bool, structure=struct)
    if n == 0:
        return vol_bool

    # volumes
    vx_vol = float(zooms[0] * zooms[1] * zooms[2]) if len(zooms) >= 3 else 1.0
    keep = np.zeros(n+1, dtype=bool)
    keep[0] = False  # background

    counts = np.bincount(lab.ravel())
    for i in range(1, n+1):
        vox = counts[i]
        mm3 = vox * vx_vol
        cond_vox = (min_vox <= 0) or (vox >= min_vox)
        cond_mm3 = (min_mm3 <= 0) or (mm3 >= min_mm3)
        if cond_vox and cond_mm3:
            keep[i] = True

    return keep[lab]

def resample_to_iso_like(nii_in_path, nii_out_path, iso=1.0, use_lcc=False,
                         morph_mode="none", morph_iters=0,
                         cleanup_min_vox=0, cleanup_min_mm3=0.0):
    """
    Resample to isotropic 'iso' mm (nearest);
    - optional: keep only the largest CC (26c)
    - NEW: light morphological smoothing (open/close) with 26c
    - NEW: remove small clusters via voxel/mm3 thresholds (26c)
    """
    img = nib.load(nii_in_path)
    A = img.affine.copy()
    # Orthonormalize and enforce target voxel size
    U, _, Vt = np.linalg.svd(A[:3, :3])
    R = U @ Vt
    A[:3, :3] = R * float(iso)
    out = nlimage.resample_img(img, target_affine=A, interpolation="nearest")
    data = (out.get_fdata() > 0.5)

    if use_lcc:
        data = keep_largest_cc_26(data)

    # NEW: light morphological smoothing (optional)
    if morph_mode in ("open", "close") and morph_iters > 0:
        struct = np.ones((3,3,3), dtype=bool)  # 26c
        if morph_mode == "open":
            data = binary_opening(data, structure=struct, iterations=int(morph_iters))
        else:
            data = binary_closing(data, structure=struct, iterations=int(morph_iters))

    # NEW: cleanup small clusters (26c)
    if (cleanup_min_vox > 0) or (cleanup_min_mm3 > 0):
        data = remove_small_components_26(
            data.astype(bool),
            zooms=out.header.get_zooms(),
            min_vox=int(cleanup_min_vox),
            min_mm3=float(cleanup_min_mm3)
        )

    data = data.astype(np.uint8)
    out_img = nib.Nifti1Image(data, out.affine, out.header)
    out_img.header.set_zooms((iso, iso, iso) + out_img.header.get_zooms()[3:])
    nib.save(out_img, nii_out_path)

def make_surface_mask(nii_in_path, nii_out_path, mode="grad", iters=1):
    """
    Create a 'surface' mask from a binary volume.
    - mode='grad': surface = dilate(vol) XOR erode(vol)  (≈ shell ~2 vox)  ← default (FD ↑)
    - mode='erode': surface = vol & ~erode(vol, iters)   (≈ shell ~iters vox)
    Fallback: if empty (tiny ROI), revert to full volume.
    """
    nii = nib.load(nii_in_path)
    vol = (nii.get_fdata() > 0)

    if not np.any(vol):
        nib.save(nib.Nifti1Image(vol.astype(np.uint8), nii.affine, nii.header), nii_out_path)
        return

    struct = np.ones((3,3,3), dtype=bool)  # 26-connectivity

    if mode == "grad":
        er = binary_erosion(vol, structure=struct, iterations=1, border_value=0)
        di = binary_dilation(vol, structure=struct, iterations=1, border_value=0)
        surf = np.logical_xor(di, er)
    else:  # 'erode'
        iters = max(1, int(iters))
        er = binary_erosion(vol, structure=struct, iterations=iters, border_value=0)
        surf = vol & (~er)

    if not np.any(surf):
        surf = vol  # fallback if too thin

    nib.save(nib.Nifti1Image(surf.astype(np.uint8), nii.affine, nii.header), nii_out_path)

# -----------------------
# Main
# -----------------------
def parse_args():
    ap = argparse.ArgumentParser(
        description="FSL + AAL (MNI→native NN) → cortical ROIs (AAL-90) → ISO 1mm → (optional LCC) → SURFACE → fractalbrain (FD)."
    )
    ap.add_argument("--t1", required=True, help="Path to T1 NIfTI (.nii or .nii.gz)")
    ap.add_argument("--out-root", required=True, help="Output folder (will be created)")
    ap.add_argument("--subject", default="sub-Example", help="Subject prefix for outputs (default: sub-Example)")
    ap.add_argument("--voxel", type=float, default=1.0, help="Isotropic voxel size for FD (default 1.0 mm)")
    ap.add_argument("--run-fract", action="store_true", help="Run fractalbrain.fract + fract2table at the end")

    # FD settings
    ap.add_argument("--lcc", action="store_true", help="Keep only the largest component (26c) after resampling")
    ap.add_argument("--surface-mode", choices=["grad","erode"], default="grad",
                    help="Surface mode: 'grad' (~2 vox, FD ↑) or 'erode' (~iters vox)")
    ap.add_argument("--surface-iters", type=int, default=1,
                    help="Thickness for 'erode' mode (default 1)")

    # NEW: Noise filtering / component cleanup
    ap.add_argument("--cleanup-min-vox", type=int, default=0,
                    help="Threshold to remove small clusters (in voxels, 0=OFF)")
    ap.add_argument("--cleanup-min-mm3", type=float, default=0.0,
                    help="Threshold to remove small clusters (in mm^3, 0=OFF)")
    ap.add_argument("--morph-smooth", choices=["none","open","close"], default="none",
                    help="Light morphological smoothing (none/open/close)")
    ap.add_argument("--morph-iters", type=int, default=0,
                    help="Iterations for morphological smoothing (0=OFF)")

    return ap.parse_args()

def main():
    args = parse_args()
    check_fsl()

    t1_path  = os.path.abspath(args.t1)
    out_root = os.path.abspath(args.out_root)
    subj     = args.subject
    os.makedirs(out_root, exist_ok=True)

    work = os.path.join(out_root, "work_fsl"); os.makedirs(work, exist_ok=True)
    rois_dir = os.path.join(out_root, "ROIs_native", subj); os.makedirs(rois_dir, exist_ok=True)

    # FSL env: output .nii.gz
    env = os.environ.copy()
    env["FSLOUTPUTTYPE"] = "NIFTI_GZ"

    # 0) Standard reorientation
    t1_std = os.path.join(work, "T1_std.nii.gz")
    run(["fslreorient2std", t1_path, t1_std], env=env)

    # 1) BET (brain extraction)
    t1_brain = os.path.join(work, "T1_std_brain.nii.gz")
    run(["bet", t1_std, t1_brain, "-R", "-f", "0.3", "-g", "0"], env=env)

    # 2) FLIRT (affine T1_brain -> MNI152 2mm brain)
    mni_brain_2mm = os.path.join(os.environ.get("FSLDIR", "/usr/share/fsl/6.0"),
                                 "data", "standard", "MNI152_T1_2mm_brain.nii.gz")
    t1_to_mni_mat = os.path.join(work, "T1_to_MNI_affine.mat")
    t1_affine_to_mni = os.path.join(work, "T1_affine_to_MNI_2mm.nii.gz")
    run([
        "flirt", "-in", t1_brain, "-ref", mni_brain_2mm,
        "-omat", t1_to_mni_mat, "-out", t1_affine_to_mni, "-dof", "12"
    ], env=env)

    # 3) FNIRT (nonlinear) — input = non-BET T1; ref = MNI 2mm; 2mm config + refmask 2mm
    mni_head_2mm = os.path.join(os.environ.get("FSLDIR", "/usr/share/fsl/6.0"),
                                "data", "standard", "MNI152_T1_2mm.nii.gz")
    mni_mask_2mm = os.path.join(os.environ.get("FSLDIR", "/usr/share/fsl/6.0"),
                                "data", "standard", "MNI152_T1_2mm_brain_mask_dil.nii.gz")
    t1_nlin_to_mni = os.path.join(work, "T1_nlin_to_MNI_2mm.nii.gz")
    t1_to_mni_warp = os.path.join(work, "T1_to_MNI_warp")
    run([
        "fnirt",
        f"--in={t1_std}",
        f"--aff={t1_to_mni_mat}",
        f"--ref={mni_head_2mm}",
        f"--refmask={mni_mask_2mm}",
        f"--iout={t1_nlin_to_mni}",
        f"--cout={t1_to_mni_warp}",
        "--config=T1_2_MNI152_2mm"
    ], env=env)

    # 4) invwarp: generate inverse warp (MNI -> native)
    mni_to_t1_warp_inv = os.path.join(work, "MNI_to_T1_warp_inv")
    run([
        "invwarp", "-w", t1_to_mni_warp, "-o", mni_to_t1_warp_inv, "-r", t1_std
    ], env=env)

    # 5) Fetch AAL (MNI) via nilearn, save as NIfTI
    print("[INFO] Fetch AAL SPM12 via nilearn (MNI)…")
    aal = datasets.fetch_atlas_aal(version="SPM12")
    aal_mni_src = aal["maps"]  # NIfTI MNI
    aal_mni_path = os.path.join(work, "AAL_SPM12_MNI.nii.gz")
    nib.save(nib.load(aal_mni_src), aal_mni_path)
    print("[OK] AAL MNI:", aal_mni_path)

    # 6) applywarp (MNI atlas -> native) with nearest-neighbor
    aal_native = os.path.join(work, "AAL_native.nii.gz")
    run([
        "applywarp",
        "-i", aal_mni_path,
        "-r", t1_std,
        "-w", mni_to_t1_warp_inv,
        "--interp=nn",
        "-o", aal_native
    ], env=env)

    # Sanity: any labels?
    tmp = nib.load(aal_native)
    vals = np.unique(np.rint(tmp.get_fdata()).astype(np.int32))
    nz = vals[vals != 0]
    print(f"[DBG] AAL_native unique labels (nonzero): n={len(nz)}, min..max=" +
          (f"{nz.min()}..{nz.max()}" if len(nz) else "NA..NA"))
    if len(nz) == 0:
        raise RuntimeError("No non-zero label after warp. Check registration and FSL references.")

    # 6b) Diagnostic: present vs expected AAL-90
    data_native = np.rint(nib.load(aal_native).get_fdata()).astype(np.int32)
    present = set(int(v) for v in np.unique(data_native) if v != 0)
    expected90 = aal90_ids_from_nilearn_values_correct()
    missing = sorted(expected90 - present)
    extra   = sorted(present - expected90)
    print(f"[DBG] AAL-90 expected: {len(expected90)} (≈90)")
    print(f"[DBG] Present after warp: {len(present)}")
    print(f"[DBG] Intersection (explodable): {len(present & expected90)}")
    if missing:
        print("[WARN] AAL-90 labels missing after warp:", missing[:20], "…")
    if extra:
        print("[INFO] Labels present but outside AAL-90:", extra[:20], "…")

    # 7) Split into ROIs (AAL-90 cortex-only)
    tmp_rois = os.path.join(work, "ROIs_tmp", subj); os.makedirs(tmp_rois, exist_ok=True)
    keep_ids = expected90
    print("[DBG] expected (AAL-90):", len(keep_ids))
    n_kept = explode_atlas_to_rois(aal_native, tmp_rois, keep_ids=keep_ids)
    print(f"[INFO] AAL cortical ROIs (name-filtered) created: {n_kept}")

    # 8) Prepare ROIs for FD — ISO resample → (optional LCC) → (NEW cleanup) → SURFACE
    roi_files = sorted(glob.glob(os.path.join(tmp_rois, "roi-*.nii.gz")))
    iso_dir = os.path.join(out_root, "ROIs_iso", subj); os.makedirs(iso_dir, exist_ok=True)
    surface_dir = os.path.join(out_root, "ROIs_surface", subj); os.makedirs(surface_dir, exist_ok=True)

    print(f"[INFO] Resample {args.voxel:.1f}mm iso (nearest) → "
          f"{'LCC(26c) → ' if args.lcc else ''}"
          f"{'morph:%s@%d → ' % (args.morph_smooth, args.morph_iters) if args.morph_smooth!='none' and args.morph_iters>0 else ''}"
          f"{'cleanup(min_vox=%d,min_mm3=%.2f) → ' % (args.cleanup_min_vox, args.cleanup_min_mm3) if (args.cleanup_min_vox>0 or args.cleanup_min_mm3>0) else ''}"
          f"surface ({args.surface_mode})…")

    for f in roi_files:
        f_iso = os.path.join(iso_dir, os.path.basename(f))  # same name
        resample_to_iso_like(
            f, f_iso,
            iso=args.voxel,
            use_lcc=args.lcc,
            morph_mode=args.morph_smooth,
            morph_iters=args.morph_iters,
            cleanup_min_vox=args.cleanup_min_vox,
            cleanup_min_mm3=args.cleanup_min_mm3
        )

        f_surf = os.path.join(surface_dir, os.path.basename(f).replace(".nii.gz", "_surface_.nii.gz"))
        make_surface_mask(f_iso, f_surf, mode=args.surface_mode, iters=args.surface_iters)

    final_rois_dir = surface_dir
    print("[OK] ROIs 'surface@{:.1f}mm' ready in: {}".format(args.voxel, final_rois_dir))

    # 9) Lists for fractalbrain
    prefixes_path = os.path.join(out_root, "prefixes_list.txt")
    nifti_list   = os.path.join(out_root, "NIfTI_list.txt")
    with open(prefixes_path, "w", encoding="utf-8") as fp, open(nifti_list, "w", encoding="utf-8") as fi:
        for f in sorted(glob.glob(os.path.join(final_rois_dir, "roi-*.nii.gz"))):
            rid = os.path.splitext(os.path.basename(f))[0]
            fp.write(f"{subj}_{rid}\n")
            fi.write(os.path.abspath(f) + "\n")
    print("[OK] Lists written:\n   ", prefixes_path, "\n   ", nifti_list)

    # 10) fract + merge (optional)
    if args.run_fract:
        print("[INFO] Run fractalbrain.fract …")
        run([sys.executable, "-m", "fractalbrain.fract", prefixes_path, nifti_list], cwd=out_root)
        print("[INFO] Run fractalbrain.fract2table …")
        run([sys.executable, "-m", "fractalbrain.fract2table", prefixes_path, nifti_list], cwd=out_root)
        print("[OK] FD results CSV in:", out_root)

    print("\n[OK] Pipeline finished successfully.")

if __name__ == "__main__":
    sys.exit(main())
